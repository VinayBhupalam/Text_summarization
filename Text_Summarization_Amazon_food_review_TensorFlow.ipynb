{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_food_review_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8J0gIZ-WVtO",
        "colab_type": "code",
        "outputId": "b1bb7463-7520-4031-88ca-7912c31fd2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time,string\n",
        "import os,json,re,string\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1yCqcsxYgjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = {\"username\":\"vinaybhupalam\",\"key\":\"5c27e8b73e30502d96da3d5b41a37fed\"}\n",
        "if not os.path.exists('/root/.kaggle'):\n",
        "  os.mkdir('/root/.kaggle')\n",
        "  with open('/root/.kaggle/kaggle.json', 'w+') as file:\n",
        "      json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_F2e6jYndS",
        "colab_type": "code",
        "outputId": "d972f04f-b221-46b0-f6fd-4e12dbb1c58e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!kaggle datasets download -d snap/amazon-fine-food-reviews"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading amazon-fine-food-reviews.zip to /content\n",
            " 96% 233M/242M [00:03<00:00, 78.4MB/s]\n",
            "100% 242M/242M [00:03<00:00, 66.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9gQY6aqYrK9",
        "colab_type": "code",
        "outputId": "164a26a2-2b60-43aa-8969-348acaa97318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!unzip amazon-fine-food-reviews.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  amazon-fine-food-reviews.zip\n",
            "  inflating: Reviews.csv             \n",
            "  inflating: database.sqlite         \n",
            "  inflating: hashes.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cch1sXY_W-AY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text_data(text):\n",
        "  tokens = text.split() \n",
        "  # prepare regex for char filtering\n",
        "  re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "  # remove punctuation from each word\n",
        "  tokens = [re_punc.sub('', w) for w in tokens]\n",
        "  #Remove <br> and <a> strings in the text\n",
        "\n",
        "  tokens = [re.sub(\"<a>|</a>|<br>|<br />\" ,\"\",w) for w in tokens]\n",
        " \n",
        "  # remove remaining tokens that are not alphabetic and convert to lower case\n",
        "  tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "  #Adding start and end tags to the text.\n",
        "  tokens.append(\"<end>\")\n",
        "  tokens.insert(0 ,\"<start>\")\n",
        " \n",
        "  return tokens "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oly6T-qGXFdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "  data=pd.read_csv(path)\n",
        "  reviews =[]\n",
        "  summaries =[]\n",
        "  for i in range(num_examples):\n",
        "  #lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    \n",
        "    try:\n",
        "      review = data['Text'][i]\n",
        "      summary = data['Summary'][i]  \n",
        "                                \n",
        "      if review is not None and summary is not None:  \n",
        "          # print(\"Review :\" +review)\n",
        "          # print(\"summary :\" +summary)       \n",
        "          reviews.append(clean_text_data(review))\n",
        "          summaries.append(clean_text_data(summary))\n",
        "    except Exception as Error:\n",
        "     print(Error)         \n",
        "  return reviews,summaries          \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e-VJJrpYx7U",
        "colab_type": "code",
        "outputId": "c2635db2-805a-4725-8776-c067454506b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reviews,summaries = create_dataset(\"Reviews.csv\" ,4000)\n",
        "print(len(reviews))\n",
        "# data = pd.read_csv(\"Reviews.csv\")\n",
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIOn8RCNDJXG",
        "colab": {}
      },
      "source": [
        "def tokenize(lang,padding_length):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen=padding_length,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rsp1ByoikNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_distribution(text_data):\n",
        "  text_length_list = [len(text) for text in text_data]\n",
        "  return text_length_list,max(text_length_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh34BmEY0YaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding_matrix(tokenizer,model,embedding_size = 300):\n",
        "  vocabulary_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  # create an empty embedding matix\n",
        "  embedding_weights = np.zeros((vocabulary_size, embedding_size))\n",
        "\n",
        "  # create a word to index dictionary mapping\n",
        "  word2id = tokenizer.word_index\n",
        "  \n",
        "  # copy vectors from word2vec model to the words present in corpus\n",
        "  for word, index in word2id.items():\n",
        "      try:\n",
        "          embedding_weights[index, :] = model[word]\n",
        "      except KeyError:\n",
        "          #print(\"Word not found {}\" .format(word))\n",
        "          pass\n",
        "  return vocabulary_size,embedding_weights,word2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0ddn100ipai",
        "colab_type": "code",
        "outputId": "df49a7a2-712d-4b7a-8055-90605dfd6d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "review_length_distribution ,max_length_review = get_data_distribution(reviews)\n",
        "summary_length_distribution,max_length_summary = get_data_distribution(summaries)\n",
        "\n",
        "print(max_length_review,max_length_summary)\n",
        "print(len(review_length_distribution))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "921 29\n",
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lLKAhZ5k0It",
        "colab_type": "code",
        "outputId": "cae8caaf-2c90-4136-de35-b6da093cff2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "fig_dims = (15, 4)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.set(style=\"whitegrid\")\n",
        "ax = sns.boxplot(x=review_length_distribution ,ax=ax)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAD7CAYAAACPH86CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSCBMAQAAJBCmAAAAEvwvoJXu82CZlvYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAXUWWkllpfl",
        "colab_type": "code",
        "outputId": "6a83c41b-ce13-4945-dcd7-81baf06fa19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "fig_dims = (15, 4)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.set(style=\"whitegrid\")\n",
        "ax = sns.boxplot(x=summary_length_distribution ,ax=ax)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAD7CAYAAACPH86CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABAgpgCAABI+D8FLZxxd7YlIQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE4JcMBToCAt",
        "colab_type": "code",
        "outputId": "ed0a8b0c-03ff-44a2-ef19-231bf0a8836d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = np.array(summary_length_distribution)\n",
        "p = np.percentile(a, 90)\n",
        "print(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkGwoV99oK18",
        "colab_type": "code",
        "outputId": "62117d85-d8f9-4bc6-ad31-b8512fa2f86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = np.array(review_length_distribution)\n",
        "p = np.percentile(a, 90)\n",
        "print(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138.10000000000014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJl7R5u-yE0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_tensor ,review_tokenizer = tokenize(reviews, max_length_review)\n",
        "summary_tensor ,summary_tokenizer = tokenize(summaries, max_length_summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCpFr80izzBu",
        "colab_type": "code",
        "outputId": "5906e261-03d4-45be-98d5-2b63cfbe0201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(review_tensor.shape)\n",
        "print(summary_tensor.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 921)\n",
            "(1400, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwetBw3M1Q92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu05hx5F3M-W",
        "colab_type": "text"
      },
      "source": [
        "Mount the google Drive and load the word2vec embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23892nI2sgLz",
        "colab_type": "code",
        "outputId": "b47e041c-b0b7-4a1f-d6ef-30db16bc40f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toKsjwu01sx-",
        "colab_type": "code",
        "outputId": "b5c336f7-4e87-4ad9-b882-53777fdbcaf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzLotsZX1Sjm",
        "colab_type": "code",
        "outputId": "e3603d1e-53c4-4ca1-ad88-6ab71425ab52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "# load the Stanford GloVe model\n",
        "filename = 'GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E78AF4Ax1vyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size_rev,embed_matrix_rev,word2id_rev = get_embedding_matrix(review_tokenizer,model)\n",
        "vocab_size_sum,embed_matrix_sum,word2id_sum = get_embedding_matrix(summary_tokenizer,model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYPRsARL2-j5",
        "colab_type": "text"
      },
      "source": [
        "Train-Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-fLBE442dz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(review_tensor, summary_tensor, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ5EnwBG2d31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 32\n",
        "steps_per_epoch = int(len(input_tensor_train)/BATCH_SIZE)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk1HVDmW4Idp",
        "colab_type": "code",
        "outputId": "3f5264f0-bb4b-464b-e855-f11a83e037ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 921]), TensorShape([32, 29]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgWGtLY_5BRr",
        "colab_type": "text"
      },
      "source": [
        "Encoder Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZ2rI24i3jFg",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz ,embedding_matrix):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim ,weights = [embedding_matrix] ,trainable = True)\n",
        "    self.LSTM = tf.keras.layers.LSTM(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    #self.BiLSTM = tf.keras.layers.Bidirectional(self.LSTM)\n",
        "    \n",
        "\n",
        "  def call(self, x, hidden_state,cell_state):\n",
        "    x = self.embedding(x)\n",
        "    output, hidden_state, cell_state = self.LSTM(x, initial_state = [hidden_state ,cell_state])\n",
        "    return output, hidden_state, cell_state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    #print(self.LSTM.state_size)\n",
        "    hidden_state = tf.zeros((self.batch_sz, self.enc_units))\n",
        "    cell_state = tf.zeros((self.batch_sz, self.enc_units))\n",
        "    return hidden_state , cell_state "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrQZqZxk5QQu",
        "colab_type": "code",
        "outputId": "eb86fdb4-6895-42d7-bef8-e2c6a0df4cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "encoder = Encoder(vocab_size_rev, 300, 1024, 32 , embed_matrix_rev)\n",
        "print(example_input_batch.shape)\n",
        "# sample input\n",
        "sample_hidden_init, sample_cell_init = encoder.initialize_hidden_state()\n",
        "enc_output, sample_hidden, sample_cell = encoder(example_input_batch, sample_hidden_init ,sample_cell_init)\n",
        "print ('Encoder cell state shape: (batch size, sequence length, units) {}'.format(sample_cell.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
        "print ('Encoder Output state shape: (batch size, sequence length, units) {}'.format(enc_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 921)\n",
            "Encoder cell state shape: (batch size, sequence length, units) (32, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (32, 1024)\n",
            "Encoder Output state shape: (batch size, sequence length, units) (32, 921, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syg-r8dJMdFC",
        "colab_type": "code",
        "outputId": "344ac73a-a42a-4e89-95e8-51e0531c66da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     multiple                  2371800   \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               multiple                  5427200   \n",
            "=================================================================\n",
            "Total params: 7,799,000\n",
            "Trainable params: 7,799,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq5MEFkscAC2",
        "colab_type": "text"
      },
      "source": [
        "Bahdanau Attention Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "umohpBN2OM94",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    self.Wc = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    #print(\"query_timw_axis shape/decoder hidden state {}\" .format(query_with_time_axis.shape))\n",
        "    #print(\"Initial Encoder output shape {}\" .format(values.shape))\n",
        "   \n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    \n",
        "    #print(\"Hidden state after NN shape {}\" .format(self.W1(query_with_time_axis).shape))\n",
        "    #print(\"Encoder output shape after NN is {}\" .format(self.W2(values).shape))\n",
        "    #print(\"Coverage vector shape afer NN is {}\" .format(self.Wc(previous_step_coverage).shape))\n",
        "\n",
        "    x = self.W1(query_with_time_axis) + self.W2(values)\n",
        "    #print(\"Shape before tanh activation shape {}\" .format(x.shape))\n",
        "   \n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    #print(\"Attention weights shape {}\" .format(attention_weights.shape))\n",
        "   # coverage_vector = previous_step_coverage + attention_weights\n",
        "    \n",
        "    #print(\"Coverage vector shape is {}\" .format(coverage_vector.shape))\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4PdfnsR80IW",
        "colab_type": "code",
        "outputId": "332f1fc2-74b8-4b4e-b523-78cbc29582c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "#coverage_vector = tf.cast(tf.fill([32,max_length_review,1] ,0) , dtype=tf.float32)\n",
        "#print(\"Initial Coverage Vector.shape {} \" .format(coverage_vector.shape))\n",
        "#print(coverage_vector.dtype)\n",
        "context_vector,attention_weights = attention_layer(sample_hidden, enc_output)\n",
        "\n",
        "#print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights shape: (batch_size, sequence_length, 1) (32, 921, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObusRgtNb9pY",
        "colab_type": "text"
      },
      "source": [
        "Decoder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHpKA-zY9LLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz,embedding_matrix):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim ,weights = [embedding_matrix] ,trainable = True)\n",
        "    self.LSTM = tf.keras.layers.LSTM(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden_state,cell_state, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector,attention_weights = self.attention(hidden_state , enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output,hidden_state,cell_state = self.LSTM(x ,initial_state = [hidden_state ,cell_state])\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(hidden_state, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    x = tf.nn.softmax(x)\n",
        "\n",
        "    return x, hidden_state,cell_state,attention_weights,context_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3HbSdvH94j9",
        "colab_type": "code",
        "outputId": "35f84889-6e8c-4cc3-9a04-e0c9c3e861f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder = Decoder(vocab_size_sum, 300, 1024, 32,embed_matrix_sum)\n",
        "\n",
        "sample_decoder_output, _, _,_,_ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden,sample_cell, enc_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (32, 1508)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC02N8Rr-WuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "     reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "   \n",
        "  #loss_coverage = 0.1*tf.reduce_sum(tf.minimum(attention_weights, context_vector, \"Smallest\"))\n",
        "  #loss_ = loss_ + loss_coverage\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Df9CnVBfOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden,enc_cell):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output,enc_hidden_state, enc_cell_state = encoder(inp, enc_hidden,enc_cell)\n",
        "\n",
        "    dec_hidden = enc_hidden_state\n",
        "    dec_cell = enc_cell_state \n",
        "\n",
        "    dec_input = tf.expand_dims([summary_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    coverage_vector =  tf.cast(tf.fill([32,max_length_review,1] ,0) , dtype=tf.float32)\n",
        "    for t in range(1, targ.shape[1]):\n",
        "     \n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, dec_cell,attention_vector,context_vector = decoder(dec_input, dec_hidden, dec_cell,enc_output)\n",
        "      \n",
        "            \n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables  \n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPDeo1SXcIB3",
        "colab_type": "text"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAXrZyrcBhLV",
        "colab_type": "code",
        "outputId": "c5b443b3-3e9b-4596-da57-0d163187a75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        }
      },
      "source": [
        "EPOCHS = 50\n",
        "total_loss_epoch = []\n",
        "for epoch in range(EPOCHS):\n",
        "  #print(epoch)\n",
        "  start = time.time()\n",
        "  enc_hidden,enc_cell = encoder.initialize_hidden_state()\n",
        "  total_loss = 0  \n",
        "  \n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):    \n",
        "    batch_loss = train_step(inp, targ, enc_hidden,enc_cell)\n",
        "    #print(\"Epoch {} batch {} loss {}\" .format(epoch,batch,batch_loss) )\n",
        "    total_loss += batch_loss  \n",
        "\n",
        "  total_loss_epoch.append(total_loss/steps_per_epoch)\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss/steps_per_epoch))\n",
        "  #print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.2729\n",
            "Epoch 2 Loss 0.2557\n",
            "Epoch 3 Loss 0.2433\n",
            "Epoch 4 Loss 0.2353\n",
            "Epoch 5 Loss 0.2289\n",
            "Epoch 6 Loss 0.2311\n",
            "Epoch 7 Loss 0.2250\n",
            "Epoch 8 Loss 0.2172\n",
            "Epoch 9 Loss 0.2107\n",
            "Epoch 10 Loss 0.2060\n",
            "Epoch 11 Loss 0.2029\n",
            "Epoch 12 Loss 0.2012\n",
            "Epoch 13 Loss 0.1956\n",
            "Epoch 14 Loss 0.1915\n",
            "Epoch 15 Loss 0.1877\n",
            "Epoch 16 Loss 0.1835\n",
            "Epoch 17 Loss 0.1813\n",
            "Epoch 18 Loss 0.1760\n",
            "Epoch 19 Loss 0.1726\n",
            "Epoch 20 Loss 0.1747\n",
            "Epoch 21 Loss 0.2130\n",
            "Epoch 22 Loss 0.1973\n",
            "Epoch 23 Loss 0.1856\n",
            "Epoch 24 Loss 0.1760\n",
            "Epoch 25 Loss 0.1697\n",
            "Epoch 26 Loss 0.1632\n",
            "Epoch 27 Loss 0.1605\n",
            "Epoch 28 Loss 0.1569\n",
            "Epoch 29 Loss 0.1533\n",
            "Epoch 30 Loss 0.1485\n",
            "Epoch 31 Loss 0.1469\n",
            "Epoch 32 Loss 0.1446\n",
            "Epoch 33 Loss 0.1383\n",
            "Epoch 34 Loss 0.1364\n",
            "Epoch 35 Loss 0.1332\n",
            "Epoch 36 Loss 0.1292\n",
            "Epoch 37 Loss 0.1239\n",
            "Epoch 38 Loss 0.1190\n",
            "Epoch 39 Loss 0.1142\n",
            "Epoch 40 Loss 0.1096\n",
            "Epoch 41 Loss 0.1051\n",
            "Epoch 42 Loss 0.1045\n",
            "Epoch 43 Loss 0.1105\n",
            "Epoch 44 Loss 0.0993\n",
            "Epoch 45 Loss 0.0904\n",
            "Epoch 46 Loss 0.0850\n",
            "Epoch 47 Loss 0.0824\n",
            "Epoch 48 Loss 0.0781\n",
            "Epoch 49 Loss 0.0727\n",
            "Epoch 50 Loss 0.0683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uk_mEKXj0lx",
        "colab_type": "code",
        "outputId": "5da0aefc-ff82-4efa-eba6-e8fa6b25ada2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "print(total_loss_epoch)\n",
        "x_axis_epochs = [i for i in range(0,EPOCHS)]\n",
        "plt.plot(x_axis_epochs, total_loss_epoch)\n",
        "plt.xlabel(\"Number of Epoch\")\n",
        "plt.ylabel(\"loss in each epoch\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=0.27293777>, <tf.Tensor: shape=(), dtype=float32, numpy=0.25567347>, <tf.Tensor: shape=(), dtype=float32, numpy=0.24325663>, <tf.Tensor: shape=(), dtype=float32, numpy=0.23530707>, <tf.Tensor: shape=(), dtype=float32, numpy=0.22891794>, <tf.Tensor: shape=(), dtype=float32, numpy=0.23114273>, <tf.Tensor: shape=(), dtype=float32, numpy=0.2250393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.21718915>, <tf.Tensor: shape=(), dtype=float32, numpy=0.2107033>, <tf.Tensor: shape=(), dtype=float32, numpy=0.20599978>, <tf.Tensor: shape=(), dtype=float32, numpy=0.20291775>, <tf.Tensor: shape=(), dtype=float32, numpy=0.20116298>, <tf.Tensor: shape=(), dtype=float32, numpy=0.19561034>, <tf.Tensor: shape=(), dtype=float32, numpy=0.19149627>, <tf.Tensor: shape=(), dtype=float32, numpy=0.18768048>, <tf.Tensor: shape=(), dtype=float32, numpy=0.18354839>, <tf.Tensor: shape=(), dtype=float32, numpy=0.18132731>, <tf.Tensor: shape=(), dtype=float32, numpy=0.17598486>, <tf.Tensor: shape=(), dtype=float32, numpy=0.1726093>, <tf.Tensor: shape=(), dtype=float32, numpy=0.17467523>, <tf.Tensor: shape=(), dtype=float32, numpy=0.21303178>, <tf.Tensor: shape=(), dtype=float32, numpy=0.19731931>, <tf.Tensor: shape=(), dtype=float32, numpy=0.18559432>, <tf.Tensor: shape=(), dtype=float32, numpy=0.17600755>, <tf.Tensor: shape=(), dtype=float32, numpy=0.16972536>, <tf.Tensor: shape=(), dtype=float32, numpy=0.16322185>, <tf.Tensor: shape=(), dtype=float32, numpy=0.16048028>, <tf.Tensor: shape=(), dtype=float32, numpy=0.15687801>, <tf.Tensor: shape=(), dtype=float32, numpy=0.15326636>, <tf.Tensor: shape=(), dtype=float32, numpy=0.14847364>, <tf.Tensor: shape=(), dtype=float32, numpy=0.14688937>, <tf.Tensor: shape=(), dtype=float32, numpy=0.14461853>, <tf.Tensor: shape=(), dtype=float32, numpy=0.138332>, <tf.Tensor: shape=(), dtype=float32, numpy=0.13635199>, <tf.Tensor: shape=(), dtype=float32, numpy=0.13324164>, <tf.Tensor: shape=(), dtype=float32, numpy=0.12921822>, <tf.Tensor: shape=(), dtype=float32, numpy=0.12390003>, <tf.Tensor: shape=(), dtype=float32, numpy=0.11898474>, <tf.Tensor: shape=(), dtype=float32, numpy=0.11424879>, <tf.Tensor: shape=(), dtype=float32, numpy=0.10964254>, <tf.Tensor: shape=(), dtype=float32, numpy=0.10514002>, <tf.Tensor: shape=(), dtype=float32, numpy=0.10445621>, <tf.Tensor: shape=(), dtype=float32, numpy=0.11053321>, <tf.Tensor: shape=(), dtype=float32, numpy=0.099290684>, <tf.Tensor: shape=(), dtype=float32, numpy=0.090410024>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08503889>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08238852>, <tf.Tensor: shape=(), dtype=float32, numpy=0.078103095>, <tf.Tensor: shape=(), dtype=float32, numpy=0.07272095>, <tf.Tensor: shape=(), dtype=float32, numpy=0.06828767>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEMCAYAAADqG+D0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGwsEaQKB2pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  result = ''\n",
        "  \n",
        "  sentence = sentence.reshape(1,max_length_review)\n",
        "  print(sentence.shape)\n",
        "  hidden = tf.zeros((1, 300))\n",
        "  print(hidden.shape)\n",
        "  cell_state = tf.zeros((1, 300))\n",
        "  enc_output, enc_hidden, enc_cell = encoder(sentence, hidden, cell_state)\n",
        "\n",
        "  dec_cell = enc_cell\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([summary_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "  print(dec_input.shape)\n",
        "  coverage_vector =  tf.cast(tf.fill([32,max_length_review,1] ,0) , dtype=tf.float32)\n",
        "  for t in range(max_length_summary):\n",
        "    predictions, dec_hidden,dec_cell, attention_weights,context_vector = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         dec_cell,enc_output)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    #attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += summary_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if summary_tokenizer.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-ilvAcPogfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_index(index , beam_width ,vocab_size):\n",
        "  #Function to get the actual index and which decoder instance it belongs to\n",
        "  bins = list(range(0, (beam_width)*vocab_size, vocab_size))\n",
        "  bin_index = np.digitize([index],bins)  \n",
        "  if bin_index[0]!=0:\n",
        "    return (index - bins[bin_index[0] - 1] , bin_index[0])\n",
        "  else:\n",
        "    return(index, 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMzW-WokcZQv",
        "colab_type": "text"
      },
      "source": [
        "Beam Search Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTaUYVF4hJ5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "def evaluate(sentence):   \n",
        "  result = ''\n",
        "  sentence = sentence.reshape(1,max_length_review)  \n",
        "  hidden = tf.zeros((1, 1024))  \n",
        "  cell_state = tf.zeros((1, 1024))\n",
        "  enc_output, enc_hidden, enc_cell = encoder(sentence, hidden, cell_state)\n",
        "  beam_width = 3\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_cell = enc_cell\n",
        "  dec_input = tf.expand_dims([summary_tokenizer.word_index['<start>']], 0) \n",
        "  for t in range(max_length_summary):    \n",
        "   \n",
        "      #First time step of Beam Search:\n",
        "      if t==0:        \n",
        "       \n",
        "        predictions, dec_hidden,dec_cell, attention_weights,context_vector = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         dec_cell,enc_output)        \n",
        "       \n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        values,indices = tf.math.top_k(predictions[0], k=beam_width, sorted=True, name=None)\n",
        "        dec_inputs = []\n",
        "        most_likely_sentences = []        \n",
        "        indices = indices.numpy()\n",
        "        prob_likely_words =[]\n",
        "        for i in range(1,beam_width+1):\n",
        "          dec_inputs.append(tf.expand_dims([indices[i]], 0))\n",
        "          most_likely_sentences.append(summary_tokenizer.index_word[indices[i]])\n",
        "          prob_likely_words.append(values[i])   \n",
        "        \n",
        "        dec_hidden_states = [dec_hidden]*beam_width\n",
        "        dec_cell_states =[dec_cell]*beam_width       \n",
        "        continue\n",
        "      \n",
        "      dec_hidden_temp = []\n",
        "      dec_cell_temp = []\n",
        "      probality_list =[]\n",
        "     \n",
        "      for i in range(0, beam_width):     \n",
        "       \n",
        "        predictions, dec_hidden,dec_cell, attention_weights,context_vector = decoder(dec_inputs[i],\n",
        "                                                        dec_hidden_states[i],\n",
        "                                                        dec_cell_states[i],enc_output)\n",
        "        dec_hidden_temp.append(dec_hidden)\n",
        "        dec_cell_temp.append(dec_cell)\n",
        "        predictions = list(predictions[0].numpy())\n",
        "        \n",
        "        #covert predictions to list\n",
        "        for probability in predictions:\n",
        "          if probability!= 0:           \n",
        "            probality_list.append(log(probability) + prob_likely_words[i])\n",
        "      \n",
        "      most_likely_wordIndices = sorted(range(len(probality_list)), key=lambda i: probality_list[i],reverse=True)[:beam_width]      \n",
        "      prob_likely_words = [probality_list[index] for index in most_likely_wordIndices]      \n",
        "      temp_list = [get_index(index,vocab_size)for index in most_likely_wordIndices]     \n",
        "      for i in range(len(temp_list)):\n",
        "        word = summary_tokenizer.index_word[temp_list[i][0]]\n",
        "\n",
        "        if word == \"<end>\":\n",
        "          end_reached[i] = True\n",
        "          return most_likely_sentence[0]         \n",
        "\n",
        "        most_likely_sentences[i] += \" \" + word\n",
        "        decoder_num = temp_list[i][1]\n",
        "\n",
        "        #Assign decoder hidden state,cell state and input for the next time step corresponding the top words which are selected.\n",
        "        dec_hidden_states[i] = dec_hidden_temp[decoder_num]\n",
        "        dec_cell_states[i] = dec_cell_states[decoder_num]\n",
        "        dec_inputs[i] = tf.expand_dims([temp_list[i][0]], 0)                                                          \n",
        "      \n",
        "  #return the sentence with maximum probability\n",
        "  return most_likely_sentence[0]\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t1RyvS4DCGD",
        "colab_type": "code",
        "outputId": "cb2bd964-d006-43f8-d2da-0b70346c3f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sample_test_seq = input_tensor_train[0:50]\n",
        "for index,sequence in enumerate(sample_test_seq):\n",
        "  sentence = evaluate(sequence)\n",
        "\n",
        "  print('Input: %s' % (\" \".join(reviews[index])))\n",
        "  print(\"Ground Truth Summary {} \".format(\" \".join(summaries[index])))\n",
        "  print('Predicted summary: {}'.format(sentence))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'good', 'the'] [-0.8815391422478966, -1.6815021504583298, -2.255466279439186]\n",
            "Input: <start> i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most <end>\n",
            "Ground Truth Summary <start> good quality dog food <end> \n",
            "Predicted summary: great just\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['amazingly', 'my', 'best'] [-1.3329718602757714, -1.5810703197530203, -1.8460581621214829]\n",
            "Input: <start> product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo <end>\n",
            "Ground Truth Summary <start> not as advertised <end> \n",
            "Predicted summary: amazingly true to a\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'when', 'great'] [-2.3117601108442516, -2.354177173630463, -2.380908181042236]\n",
            "Input: <start> this is a confection that has been around a few centuries it is a light pillowy citrus gelatin with nuts in this case filberts and it is cut into tiny squares and then liberally coated with powdered sugar and it is a tiny mouthful of heaven not too chewy and very flavorful i highly recommend this yummy treat if you are familiar with the story of cs lewis the lion the witch and the wardrobe this is the treat that seduces edmund into selling out his brother and sisters to the witch <end>\n",
            "Ground Truth Summary <start> delight says it all <end> \n",
            "Predicted summary: good you have no\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['these', 'delicious', 'yummy'] [-1.0577609786290723, -1.545798520745473, -1.967368424220269]\n",
            "Input: <start> if you are looking for the secret ingredient in robitussin i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal <end>\n",
            "Ground Truth Summary <start> cough medicine <end> \n",
            "Predicted summary: these are\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'great', 'what'] [-1.7918837228292483, -2.6969550564233504, -2.706980519864225]\n",
            "Input: <start> great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal <end>\n",
            "Ground Truth Summary <start> great taffy <end> \n",
            "Predicted summary: good instant\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['awful', 'great', 'best'] [-0.954313590820935, -2.090433944480044, -2.253216111044184]\n",
            "Input: <start> i got a wild hair for taffy and ordered this five pound bag the taffy was all very enjoyable with many flavors watermelon root beer melon peppermint grape etc my only complaint is there was a bit too much redblack licoriceflavored pieces just not my particular favorites between me my kids and my husband this lasted only two weeks i would recommend this brand of taffy it was a delightful treat <end>\n",
            "Ground Truth Summary <start> nice taffy <end> \n",
            "Predicted summary: awful\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['wheres', 'favorite', 'these'] [-0.9504022865964787, -2.258661224808817, -2.616121799754911]\n",
            "Input: <start> this saltwater taffy had great flavors and was very soft and chewy each candy was individually wrapped well none of the candies were stuck together which did happen in the expensive version fralingers would highly recommend this candy i served it at a beachthemed party and everyone loved it <end>\n",
            "Ground Truth Summary <start> great just as good as the expensive brands <end> \n",
            "Predicted summary: wheres the vinegar\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['a', 'best', 'good'] [-1.1374743963701694, -2.158327401525445, -2.613612565463879]\n",
            "Input: <start> this taffy is so good it is very soft and chewy the flavors are amazing i would definitely recommend you buying it very satisfying <end>\n",
            "Ground Truth Summary <start> wonderful tasty taffy <end> \n",
            "Predicted summary: a little too sweet\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'excellent', 'not'] [-0.7572887976455756, -3.185363182812664, -3.3604816678711313]\n",
            "Input: <start> right now im mostly just sprouting this so my cats can eat the grass they love it i rotate it around with wheatgrass and rye too <end>\n",
            "Ground Truth Summary <start> yay barley <end> \n",
            "Predicted summary: good stuff\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['best', 'one', 'beautiful'] [-0.9891698865787446, -1.8089397256541966, -2.9864041142184887]\n",
            "Input: <start> this is a very healthy dog food good for their digestion also good for small puppies my dog eats her required amount at every feeding <end>\n",
            "Ground Truth Summary <start> healthy dog food <end> \n",
            "Predicted summary: best by the best\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'better', 'an'] [-0.5417872660693273, -2.030908721033587, -2.168497170230693]\n",
            "Input: <start> i dont know if its the cactus or the tequila or just the unique combination of ingredients but the flavour of this hot sauce makes it one of a kind we picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away when we realized that we simply couldnt find it anywhere in our city we were bummedbr br now because of the magic of the internet we have a case of the sauce and are ecstatic because of itbr br if you love hot saucei mean really love hot sauce but dont want a sauce that tastelessly burns your throat grab a bottle of tequila picante gourmet de inclan just realize that once you taste it you will never want to use any other saucebr br thank you for the personal incredible service <end>\n",
            "Ground Truth Summary <start> the best hot sauce in the world <end> \n",
            "Predicted summary: great for my\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['down', 'another', 'why'] [-1.7023986761821939, -2.338273479377454, -2.791186778806255]\n",
            "Input: <start> one of my boys needed to lose some weight and the other didnt i put this food on the floor for the chubby guy and the proteinrich no byproduct food up higher where only my skinny boy can jump the higher food sits going stale they both really go for this food and my chubby boy has been losing about an ounce a week <end>\n",
            "Ground Truth Summary <start> my cats love this diet food better than their regular food <end> \n",
            "Predicted summary: down the drain\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'wonderful', 'the'] [-0.2968232091157843, -2.015059107485542, -3.0967881416137395]\n",
            "Input: <start> my cats have been happily eating felidae platinum for more than two years i just got a new bag and the shape of the food is different they tried the new food when i first put it in their bowls and now the bowls sit full and the kitties will not touch the food ive noticed similar reviews related to formula changes in the past unfortunately i now need to find a new food that my cats will eat <end>\n",
            "Ground Truth Summary <start> my cats are not fans of the new food <end> \n",
            "Predicted summary: great deal\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['my', 'great', 'yummy'] [-0.5441988150507145, -1.4782713004867833, -3.52901103167967]\n",
            "Input: <start> good flavor these came securely packed they were fresh and delicious i love these twizzlers <end>\n",
            "Ground Truth Summary <start> fresh and greasy <end> \n",
            "Predicted summary: my dog loves these\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['best', 'the', 'not'] [-1.1225680406748813, -1.832203347497461, -2.1590799781388905]\n",
            "Input: <start> the strawberry twizzlers are my guilty pleasure yummy six pounds will be around for a while with my son and i <end>\n",
            "Ground Truth Summary <start> strawberry twizzlers yummy <end> \n",
            "Predicted summary: best for is\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['where', 'tastes', 'its'] [-1.3448964750229446, -2.450793875599816, -2.5677801105436417]\n",
            "Input: <start> my daughter loves twizzlers and this shipment of six pounds really hit the spot its exactly what you would expectsix packages of strawberry twizzlers <end>\n",
            "Ground Truth Summary <start> lots of twizzlers just what you expect <end> \n",
            "Predicted summary: where has this\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['shipped', 'the', 'this'] [-1.7535284041811383, -1.8083275045176828, -1.968670605143784]\n",
            "Input: <start> i love eating them and they are good for watching tv and looking at movies it is not too sweet i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them <end>\n",
            "Ground Truth Summary <start> poor taste <end> \n",
            "Predicted summary: shipped great\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['the', 'great', 'this'] [-0.47554597923277436, -2.9379340694842977, -2.9913211997622295]\n",
            "Input: <start> i am very satisfied with my twizzler purchase i shared these with others and we have all enjoyed them i will definitely be ordering more <end>\n",
            "Ground Truth Summary <start> love it <end> \n",
            "Predicted summary: the spice will grow\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['natural', 'sublime', 'make'] [-1.6167732333630471, -2.1298915162485095, -2.652279523806332]\n",
            "Input: <start> twizzlers strawberry my childhood favorite candy made in lancaster pennsylvania by y s candies inc one of the oldest confectionery firms in the united states now a subsidiary of the hershey company the company was established in as young and smylie they also make apple licorice twists green color and blue raspberry licorice twists i like them allbr br i keep it in a dry cool place because is not recommended it to put it in the fridge according to the guinness book of records the longest licorice twist ever made measured feet m and weighted pounds kg and was made by y s candies inc this recordbreaking twist became a guinness world record on july this product is kosher thank you <end>\n",
            "Ground Truth Summary <start> great sweet candy <end> \n",
            "Predicted summary: natural energy boost\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['mushy', 'its', 'home'] [-0.4196887491403875, -2.2222734348989905, -2.923036641542711]\n",
            "Input: <start> candy was delivered very fast and was purchased at a reasonable price i was home bound and unable to get to a store so this was perfect for me <end>\n",
            "Ground Truth Summary <start> home delivered twizlers <end> \n",
            "Predicted summary: mushy\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['tasty', 'excellent', 'best'] [-0.556404043729953, -1.9701232283778805, -2.623717291236675]\n",
            "Input: <start> my husband is a twizzlers addict weve bought these many times from amazon because were government employees living overseas and cant get them in the country we are assigned to theyve always been fresh and tasty packed well and arrive in a timely manner <end>\n",
            "Ground Truth Summary <start> always fresh <end> \n",
            "Predicted summary: tasty fruit\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'best', 'great'] [-0.9847411577219024, -1.8903836181253368, -2.3037137326694697]\n",
            "Input: <start> i bought these for my husband who is currently overseas he loves these and apparently his staff likes them alsobr there are generous amounts of twizzlers in each bag and this was well worth the price a strawberry bags pack of <end>\n",
            "Ground Truth Summary <start> twizzlers <end> \n",
            "Predicted summary: good coffee\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'awesome', 'not'] [-1.6711301145974977, -2.5957665423075142, -2.760889443038701]\n",
            "Input: <start> i can remember buying this candy as a kid and the quality hasnt dropped in all these years still a superb product you wont be disappointed with <end>\n",
            "Ground Truth Summary <start> delicious product <end> \n",
            "Predicted summary: good stuff\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['my', 'the', 'best'] [-1.255928464982713, -1.4734311541463903, -1.9577717929986949]\n",
            "Input: <start> i love this candy after weight watchers i had to cut back but still have a craving for it <end>\n",
            "Ground Truth Summary <start> twizzlers <end> \n",
            "Predicted summary: my new granola bar\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'excellent', 'this'] [-1.73899317776362, -2.001666967655786, -2.320198531521079]\n",
            "Input: <start> i have lived out of the us for over yrs now and i so miss my twizzlers when i go back to visit or someone visits me i always stock up all i can say is yumbr sell these in mexico and you will have a faithful buyer more often than im able to buy them right now <end>\n",
            "Ground Truth Summary <start> please sell these in mexico <end> \n",
            "Predicted summary: great coffee terrible\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['best', 'not', 'the'] [-0.5218378534402253, -2.6434069922143513, -3.1482087052397696]\n",
            "Input: <start> product received is as advertisedbr br a strawberry bags pack of <end>\n",
            "Ground Truth Summary <start> twizzlers strawberry <end> \n",
            "Predicted summary: best chips ever\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['now', 'good', 'the'] [-1.6902158565760135, -1.7278678807406211, -1.9411862122448944]\n",
            "Input: <start> the candy is just red no flavor just plan and chewy i would never buy them again <end>\n",
            "Ground Truth Summary <start> nasty no flavor <end> \n",
            "Predicted summary: now a staple\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'delicious', 'these'] [-0.31737164311812277, -2.051137218817787, -2.845526011091665]\n",
            "Input: <start> i was so glad amazon carried these batteries i have a hard time finding them elsewhere because they are such a unique size i need them for my garage door openerbr great deal for the price <end>\n",
            "Ground Truth Summary <start> great bargain for the price <end> \n",
            "Predicted summary: great buy\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['love', 'great', 'awsome'] [-1.6872157306043012, -1.913729562614457, -2.219168148065663]\n",
            "Input: <start> i got this for my mum who is not diabetic but needs to watch her sugar intake and my father who simply chooses to limit unnecessary sugar intake shes the one with the sweet tooth they both loved these toffees you would never guess that theyre sugarfree and its so great that you can eat them pretty much guilt free i was so impressed that ive ordered some for myself w dark chocolate to take to the office so ill eat them instead of snacking on sugary sweetsbr these are just excellent <end>\n",
            "Ground Truth Summary <start> yummy <end> \n",
            "Predicted summary: love the\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'great', 'the'] [-0.33876753762972633, -2.889841551252502, -3.013025306957624]\n",
            "Input: <start> i dont know if its the cactus or the tequila or just the unique combination of ingredients but the flavour of this hot sauce makes it one of a kind we picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away when we realized that we simply couldnt find it anywhere in our city we were bummedbr br now because of the magic of the internet we have a case of the sauce and are ecstatic because of itbr br if you love hot saucei mean really love hot sauce but dont want a sauce that tastelessly burns your throat grab a bottle of tequila picante gourmet de inclan just realize that once you taste it you will never want to use any other saucebr br thank you for the personal incredible service <end>\n",
            "Ground Truth Summary <start> the best hot sauce in the world <end> \n",
            "Predicted summary: good food\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'delicious', 'just'] [-0.73731251610422, -1.6856654030802682, -2.970404355182941]\n",
            "Input: <start> i have never been a huge coffee fan however my mother purchased this little machine and talked me into trying the latte macciato no coffee shop has a better one and i like most of the other products too as a usually noncoffee drinkerbr the little dolche guesto machine is super easy to use and prepares a really good coffeelattecappuccinoetc in less than a minute if water is heated up i would recommend the dolce gusto to anyone too good for the price and iam getting one myself <end>\n",
            "Ground Truth Summary <start> great machine <end> \n",
            "Predicted summary: great product to ever\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'wonderful', 'the'] [-0.5502243719723007, -1.6154166461080999, -3.275819882622386]\n",
            "Input: <start> this offer is a great price and a great taste thanks amazon for selling this productbr br staral <end>\n",
            "Ground Truth Summary <start> this is my taste <end> \n",
            "Predicted summary: great deal\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['best', 'tasty', 'excellent'] [-1.2285060095493046, -1.5548957596484232, -2.802831994965882]\n",
            "Input: <start> mccanns instant oatmeal is great if you must have your oatmeal but can only scrape together two or three minutes to prepare it there is no escaping the fact however that even the best instant oatmeal is nowhere near as good as even a store brand of oatmeal requiring stovetop preparation still the mccanns is as good as it gets for instant oatmeal its even better than the organic allnatural brands i have tried all the varieties in the mccanns variety pack taste good it can be prepared in the microwave or by adding boiling water so it is convenient in the extreme when time is an issuebr br mccanns use of actual cane sugar instead of high fructose corn syrup helped me decide to buy this product real sugar tastes better and is not as harmful as the other stuff one thing i do not like though is mccanns use of thickeners oats plus water plus heat should make a creamy tasty oatmeal without the need for guar gum but this is a convenience product maybe the guar gum is why after sitting in the bowl a while the instant mccanns becomes too thick and gluey <end>\n",
            "Ground Truth Summary <start> best of the instant oatmeals <end> \n",
            "Predicted summary: best stuff ever\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'best', 'excellent'] [-1.5191185818654074, -2.2930434124513237, -2.886488754892924]\n",
            "Input: <start> this is a good instant oatmeal from the best oatmeal brand it uses cane sugar instead of high fructouse corn syrup so not only does it have a better sweetness but some doctors now say that this form of sugar is better for you great on a cold morning when you dont have time to make mccanns steel cut oats the apple cinnamon is the best but the maple and brown sugar or the regular are good too plus they dont require doctoring to actually tell the three flavors apart <end>\n",
            "Ground Truth Summary <start> good instant <end> \n",
            "Predicted summary: good training flavor excellent\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['best', 'not', 'jacks'] [-0.7124726053558048, -2.7243940324622584, -2.7794087027768026]\n",
            "Input: <start> instant oatmeal can become soggy the minute the water hits the bowl mccanns instant oatmeal holds its texture has excellent flavor and is good for you all at the same time mccanns regular oat meal is excellent too but may take a bit longer to prepare than most have time for in the morning this is the best instant brand ive ever eaten and a very close second to the noninstant varietybr br mccanns instant irish oatmeal variety pack of regular apples cinnamon and maple brown sugar boxes pack of <end>\n",
            "Ground Truth Summary <start> great irish oatmeal for those in a hurry <end> \n",
            "Predicted summary: best friend treats\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['what', 'beautiful', 'disappointed'] [-1.902708466610366, -2.176456853958233, -2.5411457375826014]\n",
            "Input: <start> mccanns instant irish oatmeal variety pack of regular apples cinnamon and maple brown sugar boxes pack of br im a fan of the mccanns steelcut oats so i thought id give the instant variety a try i found it to be a hardy meal not too sweet and great for folks like me postbariatric surgery who need food that is palatable easily digestible with fiber but wont make you bloat <end>\n",
            "Ground Truth Summary <start> satisfying <end> \n",
            "Predicted summary: what happened\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['not', 'best', 'good'] [-1.0219301467513349, -2.0404782299226194, -2.5056809452947055]\n",
            "Input: <start> for those of us with celiac disease this product is a lifesaver and what could be better than getting it at almost half the price of the grocery or health food store i love mccanns instant oatmeal all flavorsbr br thanksbr abby <end>\n",
            "Ground Truth Summary <start> love gluten free oatmeal <end> \n",
            "Predicted summary: not good\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['tangy', 'i', 'love'] [-0.34428192941048097, -2.3696095927000975, -3.7630194207188015]\n",
            "Input: <start> what else do you need to know oatmeal instant make it with a half cup of lowfat milk and add raisinsnuke for seconds more expensive than kroger store brand oatmeal and maybe a little tastier or better texture or something its still just oatmeal mmm convenient <end>\n",
            "Ground Truth Summary <start> its oatmeal <end> \n",
            "Predicted summary: tangy goodness\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['forget', 'speedy', 'good'] [-2.238806865662269, -2.3499658038485642, -2.5018612691602518]\n",
            "Input: <start> i was visiting my friend nate the other morning for coffee he came out of his storage room with a packet of mccanns instant irish oatmeal he suggested that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i ended up trying the apple and cinn found it to be very tastefull when made with water or powdered milk it goes good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith <end>\n",
            "Ground Truth Summary <start> good way to start the day <end> \n",
            "Predicted summary: forget molecular gastronomy\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['i', 'these', 'delicious'] [-1.3163999268889064, -2.199445623770865, -2.3477620213185464]\n",
            "Input: <start> i ordered this for my wife as it was reccomended by our daughter she has this almost every morning and likes all flavors shes happy im happybr a instant irish oatmeal variety pack of regular apples cinnamon and maple brown sugar boxes pack of <end>\n",
            "Ground Truth Summary <start> wifes favorite breakfast <end> \n",
            "Predicted summary: i love\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['delicious', 'very', 'fresh'] [-1.495139561031023, -1.713558718228257, -2.5640202101139]\n",
            "Input: <start> the variety packs taste greatbr br i have them every morning at cents per meal i dont understand why everyone on earth isnt buying this stuff upbr br maple and brown sugar is terrific followed by apples and cinnamon followed by regular you dont get tired of the same ole thing and they taste greatbr br i just boil water from a small pot empty the packet or in a bowl pour in boiling water and watch it expand to its sizebr br taste really good and takes minutes to preparebr br not sure why everyone on earth isnt this convenient healthy very quick excellent quality and extremely cheap <end>\n",
            "Ground Truth Summary <start> why wouldnt you buy oatmeal from mcanns tastes great <end> \n",
            "Predicted summary: delicious and\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['tasty', 'good', 'very'] [-1.0202518921191217, -1.3822094264624485, -2.17228574937274]\n",
            "Input: <start> mccanns makes oatmeal for every oatmeal connoisseur whether one likes it from the raw pellet state that cooks for half an hour to the sloth addled instant which can be done in the microwave for under three minutes its all good thats for sure and the beauty of the instant variety is that it is available in different flavors as well as regularbr this variety pack allows different tastes to be explored as well as giving you a chance to experience the difference between mccanns and other wellknown oatmeals what i personally like about mccanns is that it cooks up thicker and with more body than the top brand here in america the apples cinnamon though tends to be a little liquidy so you may want to experiment with the amount of water you add in my microwave the oatmeal cooks up in about one minute and twentyseven seconds so you should also watch that to get a handle on how much time and water to usebr the only bad thing if you can consider it a bad thing about this offering is that you have to buy in lot so youll end up with six tencount boxes this is good if you have a whole family of oatmealeaters but if youre a single person alone well love oatmeal <end>\n",
            "Ground Truth Summary <start> oatmeal for oatmeal lovers <end> \n",
            "Predicted summary: tasty\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['best', 'good', 'awful'] [-1.715291821273642, -1.9854201725484477, -2.250281626568273]\n",
            "Input: <start> i have mccanns oatmeal every morning and by ordering it from amazon i am able to save almost per boxbr it is a great product tastes great and very healthy <end>\n",
            "Ground Truth Summary <start> foodgreat <end> \n",
            "Predicted summary: best\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['perfect', 'buy', 'spicy'] [-0.9237492245592909, -2.7717711615979703, -3.2099034386491807]\n",
            "Input: <start> mccanns oatmeal is a good quality choice our favorite is the apples and cinnamon but we find that none of these are overly sugary for a good hot breakfast in minutes this is excellent <end>\n",
            "Ground Truth Summary <start> good hot breakfast <end> \n",
            "Predicted summary: perfect mix of the best\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['actually', 'i', 'cherry'] [-1.4370163168699956, -1.7805445883007975, -1.965078607926667]\n",
            "Input: <start> we really like the mccanns steel cut oats but find we dont cook it up too oftenbr this tastes much better to me than the grocery store brands and is just as convenientbr anything that keeps me eating oatmeal regularly is a good thing <end>\n",
            "Ground Truth Summary <start> great taste and convenience <end> \n",
            "Predicted summary: actually pretty good\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'excellent', 'this'] [-1.740946599354644, -2.002121793491975, -2.3208201493608267]\n",
            "Input: <start> this seems a little more wholesome than some of the supermarket brands but it is somewhat mushy and doesnt have quite as much flavor either it didnt pass muster with my kids so i probably wont buy it again <end>\n",
            "Ground Truth Summary <start> hearty oatmeal <end> \n",
            "Predicted summary: great coffee terrible\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['altoids', 'tastes', 'satisfying'] [-2.3398015296693293, -2.620487850891516, -2.976854987576289]\n",
            "Input: <start> good oatmeal i like the apple cinnamon the best though i wouldnt follow the directions on the package since it always comes out too soupy for my taste that could just be me since i like my oatmeal really thick to add some milk on top of <end>\n",
            "Ground Truth Summary <start> good <end> \n",
            "Predicted summary: altoids great\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'delicious', 'the'] [-0.27089556166025364, -1.890760032075375, -3.965642047028358]\n",
            "Input: <start> the flavors are good however i do not see any differce between this and oaker oats brand they are both mushy <end>\n",
            "Ground Truth Summary <start> mushy <end> \n",
            "Predicted summary: great item\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['great', 'my', 'the'] [-1.00759706091604, -1.171177974725318, -2.627010887028265]\n",
            "Input: <start> i really like the maple and brown sugar flavor the regular is fine with brown sugar added the apples and cinnamon flavor is ok this is a very quick easy and satisfying breakfast and ill order this brand again but not the variety ill get all maple and brown sugar <end>\n",
            "Ground Truth Summary <start> very good but next time i wont order the variety pack <end> \n",
            "Predicted summary: great but not these\n",
            "(1, 921)\n",
            "(1, 1024)\n",
            "['good', 'great', 'not'] [-1.0140530706180328, -1.611433812396128, -2.6655275832257317]\n",
            "Input: <start> this is the same stuff you can buy at the big box stores there is nothing healthy about it it is just carbs and sugars save your money and get something that at least has some taste <end>\n",
            "Ground Truth Summary <start> same stuff <end> \n",
            "Predicted summary: good for you but not\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}